{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear model attempts to estimate sets of observables $y$ with linear combinations of predictors $x$.\n",
    "\n",
    "---\n",
    "\n",
    "If $x$ has a single dimension, i.e. there is only one coefficient of linearity, the obtained model is univariate.\n",
    "\n",
    "If, on the other hand, $x$ has more than one dimension, i.e. each of its dimensions has a corresponding linear coefficient, the obtained model is multivariate.\n",
    "\n",
    "---\n",
    "\n",
    "Additionally, the $x$ and $y$ sets may be affected by uncertainties.\n",
    "\n",
    "Any uncertainty affecting any quantity is here assumed to stem from a normal distribution.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook attempts to summarise the best `python` tools with which each of these cases can be better tackled.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy import odr, stats\n",
    "from sklearn import linear_model\n",
    "from statsmodels.regression.linear_model import OLS, WLS\n",
    "from statsmodels.tools import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 2   # number of parameters to fit, i.e. slope and intercept\n",
    "\n",
    "real_slope = -5.3\n",
    "real_intercept = 10.7\n",
    "\n",
    "x_sigma = 0.5\n",
    "y_sigma = 3.5\n",
    "\n",
    "# create column vector of predictors\n",
    "x = np.linspace(start=-30, stop=20, num=n) + np.random.normal(loc=0, scale=x_sigma, size=(n,))\n",
    "x = x.reshape(-1, 1)\n",
    "\n",
    "x_design = tools.add_constant(x)\n",
    "\n",
    "# create column vector of observables\n",
    "y = real_slope * np.linspace(start=-30, stop=20, num=n) + real_intercept + np.random.normal(loc=0, scale=y_sigma, size=(n,))\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "x_to_predict = 6\n",
    "x_to_predict_col_vec = np.array([[1],[x_to_predict]])\n",
    "\n",
    "alpha = 1-.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `scipy.stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated slope -5.3289 ± 0.0276\n",
      "Estimated intercept 10.4126 ± 0.4229\n"
     ]
    }
   ],
   "source": [
    "# vectors need to be converted to rows\n",
    "x_row = x.flatten()\n",
    "y_row = y.flatten()\n",
    "\n",
    "sp_result = stats.linregress(x.flatten(), y_row)\n",
    "\n",
    "print(f\"Estimated slope {sp_result.slope:.4f} ± {sp_result.stderr:.4f}\\nEstimated intercept {sp_result.intercept:.4f} ± {sp_result.intercept_stderr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.5607 ± 0.9975\n"
     ]
    }
   ],
   "source": [
    "residuals = y_row - (x_row * sp_result.slope + sp_result.intercept)\n",
    "s_value = np.linalg.norm(residuals, 2) / np.sqrt(n - p)\n",
    "\n",
    "y_estimated = x_to_predict * sp_result.slope + sp_result.intercept\n",
    "\n",
    "inner_sqrt_term = (x_to_predict_col_vec.T @ np.linalg.inv(x_design.T @ x_design ) @ x_to_predict_col_vec )[0,0]\n",
    "\n",
    "one_sided_CL_magnitude = stats.t.ppf(q = 1-(alpha/2), df = n-p) * s_value * np.sqrt(inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_CL_magnitude:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.5607 ± 7.9832\n"
     ]
    }
   ],
   "source": [
    "one_sided_PL_magnitude = stats.t.ppf(q = 1-alpha/2, df = n-p) * s_value * np.sqrt(1+inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_PL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated slope -5.3289 \n",
      "Estimated intercept 10.4126 \n"
     ]
    }
   ],
   "source": [
    "sk_lm = linear_model.LinearRegression()\n",
    "sk_result = sk_lm.fit(x, y)\n",
    "\n",
    "print(f\"Estimated slope {sk_result.coef_[0,0]:.4f} \\nEstimated intercept {sk_result.intercept_[0]:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.5607 ± 0.9975\n"
     ]
    }
   ],
   "source": [
    "residuals = y_row - (x_row * sk_result.coef_[0,0] + sk_result.intercept_[0])\n",
    "s_value = np.linalg.norm(residuals, 2) / np.sqrt(n - p)\n",
    "\n",
    "y_estimated = x_to_predict * sk_result.coef_[0,0] + sk_result.intercept_[0]\n",
    "\n",
    "inner_sqrt_term = (x_to_predict_col_vec.T @ np.linalg.inv(x_design.T @ x_design ) @ x_to_predict_col_vec )[0,0]\n",
    "\n",
    "one_sided_CL_magnitude = stats.t.ppf(q = 1-(alpha/2), df = n-p) * s_value * np.sqrt(inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_CL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.5607 ± 7.9832\n"
     ]
    }
   ],
   "source": [
    "one_sided_PL_magnitude = stats.t.ppf(q = 1-alpha/2, df = n-p) * s_value * np.sqrt(1+inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_PL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.997\n",
      "Model:                            OLS   Adj. R-squared:                  0.997\n",
      "Method:                 Least Squares   F-statistic:                 3.724e+04\n",
      "Date:                Mon, 17 Mar 2025   Prob (F-statistic):          2.75e-128\n",
      "Time:                        15:57:08   Log-Likelihood:                -279.30\n",
      "No. Observations:                 100   AIC:                             562.6\n",
      "Df Residuals:                      98   BIC:                             567.8\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         10.4126      0.423     24.620      0.000       9.573      11.252\n",
      "x1            -5.3289      0.028   -192.978      0.000      -5.384      -5.274\n",
      "==============================================================================\n",
      "Omnibus:                        1.010   Durbin-Watson:                   1.464\n",
      "Prob(Omnibus):                  0.603   Jarque-Bera (JB):                1.113\n",
      "Skew:                          -0.204   Prob(JB):                        0.573\n",
      "Kurtosis:                       2.683   Cond. No.                         16.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "sm_lm = OLS(y, x_design)\n",
    "sm_result = sm_lm.fit()\n",
    "print(sm_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.5607 ± 0.9975\n"
     ]
    }
   ],
   "source": [
    "prediction = sm_result.get_prediction(x_to_predict_col_vec.T)\n",
    "\n",
    "y_estimated = prediction.predicted_mean[0]\n",
    "\n",
    "one_sided_CL_magnitude = prediction.summary_frame(alpha=alpha).mean_ci_upper.iloc[0] - prediction.predicted_mean[0]\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_CL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.5607 ± 7.9832\n"
     ]
    }
   ],
   "source": [
    "one_sided_PL_magnitude = prediction.summary_frame(alpha=alpha).obs_ci_upper.iloc[0] - prediction.predicted_mean[0]\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_PL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `statsmodels` since it is neater and there is less variable manipulation.\n",
    "\n",
    "Do not use `scikit-learn` since it doesn't even provide standard errors for the fit coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With uncertainties in $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_weights = 1/abs(np.random.normal(loc=y_sigma, scale=y_sigma/10, size=(n,)))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated slope -5.3260 \n",
      "Estimated intercept 10.4618 \n"
     ]
    }
   ],
   "source": [
    "sk_weighted_lm = linear_model.LinearRegression()\n",
    "sk_weighted_result = sk_weighted_lm.fit(x, y, sample_weight=y_weights)\n",
    "\n",
    "print(f\"Estimated slope {sk_weighted_result.coef_[0,0]:.4f} \\nEstimated intercept {sk_weighted_result.intercept_[0]:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.4942 ± 1.0083\n"
     ]
    }
   ],
   "source": [
    "residuals = y_row - (x_row * sk_weighted_result.coef_[0,0] + sk_weighted_result.intercept_[0])\n",
    "s_squared_value = sum(y_weights * residuals**2) / (n - p)\n",
    "\n",
    "y_estimated = x_to_predict * sk_weighted_result.coef_[0,0] + sk_weighted_result.intercept_[0]\n",
    "\n",
    "inner_sqrt_term = (x_to_predict_col_vec.T @ np.linalg.inv(x_design.T @ np.diag(y_weights) @ x_design ) @ x_to_predict_col_vec )[0,0]\n",
    "\n",
    "one_sided_CL_magnitude = stats.t.ppf(q = 1-(alpha/2), df = n-p) * np.sqrt(s_squared_value * inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_CL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.4942 ± 2.5394\n"
     ]
    }
   ],
   "source": [
    "one_sided_PL_magnitude = stats.t.ppf(q = 1-alpha/2, df = n-p) * np.sqrt(s_squared_value + s_squared_value * inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_PL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_weighted_lm = WLS(y, x_design, y_weights )\n",
    "sm_weighted_result = sm_weighted_lm.fit()\n",
    "# print(sm_weighted_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.4942 ± 1.0083\n"
     ]
    }
   ],
   "source": [
    "weighted_prediction = sm_weighted_result.get_prediction(x_to_predict_col_vec.T)\n",
    "\n",
    "y_estimated = weighted_prediction.predicted_mean[0]\n",
    "\n",
    "one_sided_CL_magnitude = weighted_prediction.summary_frame(alpha=alpha).mean_ci_upper.iloc[0] - weighted_prediction.predicted_mean[0]\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_CL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.4942 ± 2.5394\n"
     ]
    }
   ],
   "source": [
    "one_sided_PL_magnitude = weighted_prediction.summary_frame(alpha=alpha).obs_ci_upper.iloc[0] - weighted_prediction.predicted_mean[0]\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_PL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the `statsmodels` approach is neater and preferred.\n",
    "\n",
    "`sklearn` is also fine to be used, but some manipulation needs to be done with the variables.\n",
    "\n",
    "Do not use `scipy.odr` since it does not perform an exact weighted least squares calculation to estimate the fit parameters and instead uses the Levenberg-Marquardt-type algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With uncertainties in $x$ and $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
