{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear model attempts to estimate sets of observables $y$ with linear combinations of predictors $x$.\n",
    "\n",
    "---\n",
    "\n",
    "If $x$ has a single dimension, i.e. there is only one coefficient of linearity, the obtained model is univariate.\n",
    "\n",
    "If, on the other hand, $x$ has more than one dimension, i.e. each of its dimensions has a corresponding linear coefficient, the obtained model is multivariate.\n",
    "\n",
    "---\n",
    "\n",
    "Additionally, the $x$ and $y$ sets may be affected by uncertainties.\n",
    "\n",
    "Any uncertainty affecting any quantity is here assumed to stem from a normal distribution.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook attempts to summarise the best `python` tools with which each of these cases can be better tackled.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy import odr, stats\n",
    "from sklearn import linear_model\n",
    "from statsmodels.regression.linear_model import GLS, OLS, WLS\n",
    "from statsmodels.tools import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 2   # number of parameters to fit, i.e. slope and intercept\n",
    "\n",
    "real_slope = -5.3\n",
    "real_intercept = 10.7\n",
    "\n",
    "x_sigma = 0.5\n",
    "y_sigma = 3.5\n",
    "\n",
    "# create column vector of predictors\n",
    "x = np.linspace(start=-30, stop=20, num=n) + np.random.normal(loc=0, scale=x_sigma, size=(n,))\n",
    "x = x.reshape(-1, 1)\n",
    "\n",
    "x_design = tools.add_constant(x)\n",
    "\n",
    "# create column vector of observables\n",
    "y = real_slope * np.linspace(start=-30, stop=20, num=n) + real_intercept + np.random.normal(loc=0, scale=y_sigma, size=(n,))\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "x_to_predict = 6\n",
    "x_to_predict_col_vec = np.array([[1],[x_to_predict]])\n",
    "\n",
    "alpha = 1-.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `scipy.stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated slope -5.2957 ± 0.0264\n",
      "Estimated intercept 10.8958 ± 0.4084\n"
     ]
    }
   ],
   "source": [
    "# vectors need to be converted to rows\n",
    "x_row = x.flatten()\n",
    "y_row = y.flatten()\n",
    "\n",
    "sp_result = stats.linregress(x.flatten(), y_row)\n",
    "\n",
    "print(f\"Estimated slope {sp_result.slope:.4f} ± {sp_result.stderr:.4f}\\nEstimated intercept {sp_result.intercept:.4f} ± {sp_result.intercept_stderr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -20.8787 ± 0.9584\n"
     ]
    }
   ],
   "source": [
    "residuals = y_row - (x_row * sp_result.slope + sp_result.intercept)\n",
    "s_value = np.linalg.norm(residuals, 2) / np.sqrt(n - p)\n",
    "\n",
    "y_estimated = x_to_predict * sp_result.slope + sp_result.intercept\n",
    "\n",
    "inner_sqrt_term = (x_to_predict_col_vec.T @ np.linalg.inv(x_design.T @ x_design ) @ x_to_predict_col_vec )[0,0]\n",
    "\n",
    "one_sided_CL_magnitude = stats.t.ppf(q = 1-(alpha/2), df = n-p) * s_value * np.sqrt(inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_CL_magnitude:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -20.8787 ± 7.7356\n"
     ]
    }
   ],
   "source": [
    "one_sided_PL_magnitude = stats.t.ppf(q = 1-alpha/2, df = n-p) * s_value * np.sqrt(1+inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_PL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated slope -5.3289 \n",
      "Estimated intercept 10.4126 \n"
     ]
    }
   ],
   "source": [
    "sk_lm = linear_model.LinearRegression()\n",
    "sk_result = sk_lm.fit(x, y)\n",
    "\n",
    "print(f\"Estimated slope {sk_result.coef_[0,0]:.4f} \\nEstimated intercept {sk_result.intercept_[0]:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.5607 ± 0.9975\n"
     ]
    }
   ],
   "source": [
    "residuals = y_row - (x_row * sk_result.coef_[0,0] + sk_result.intercept_[0])\n",
    "s_value = np.linalg.norm(residuals, 2) / np.sqrt(n - p)\n",
    "\n",
    "y_estimated = x_to_predict * sk_result.coef_[0,0] + sk_result.intercept_[0]\n",
    "\n",
    "inner_sqrt_term = (x_to_predict_col_vec.T @ np.linalg.inv(x_design.T @ x_design ) @ x_to_predict_col_vec )[0,0]\n",
    "\n",
    "one_sided_CL_magnitude = stats.t.ppf(q = 1-(alpha/2), df = n-p) * s_value * np.sqrt(inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_CL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.5607 ± 7.9832\n"
     ]
    }
   ],
   "source": [
    "one_sided_PL_magnitude = stats.t.ppf(q = 1-alpha/2, df = n-p) * s_value * np.sqrt(1+inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_PL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                 4.036e+04\n",
      "Date:                Mon, 17 Mar 2025   Prob (F-statistic):          5.41e-130\n",
      "Time:                        18:43:42   Log-Likelihood:                -276.16\n",
      "No. Observations:                 100   AIC:                             556.3\n",
      "Df Residuals:                      98   BIC:                             561.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         10.8958      0.408     26.680      0.000      10.085      11.706\n",
      "x1            -5.2957      0.026   -200.896      0.000      -5.348      -5.243\n",
      "==============================================================================\n",
      "Omnibus:                        0.877   Durbin-Watson:                   2.211\n",
      "Prob(Omnibus):                  0.645   Jarque-Bera (JB):                0.830\n",
      "Skew:                          -0.217   Prob(JB):                        0.660\n",
      "Kurtosis:                       2.894   Cond. No.                         16.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "sm_lm = OLS(y, x_design)\n",
    "sm_result = sm_lm.fit()\n",
    "print(sm_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -20.8787 ± 0.9584\n"
     ]
    }
   ],
   "source": [
    "prediction = sm_result.get_prediction(x_to_predict_col_vec.T)\n",
    "\n",
    "y_estimated = prediction.predicted_mean[0]\n",
    "\n",
    "one_sided_CL_magnitude = prediction.summary_frame(alpha=alpha).mean_ci_upper.iloc[0] - prediction.predicted_mean[0]\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_CL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -20.8787 ± 7.7356\n"
     ]
    }
   ],
   "source": [
    "one_sided_PL_magnitude = prediction.summary_frame(alpha=alpha).obs_ci_upper.iloc[0] - prediction.predicted_mean[0]\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_PL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `statsmodels` since it is neater and there is less variable manipulation.\n",
    "\n",
    "Do not use `scikit-learn` since it doesn't even provide standard errors for the fit coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With uncertainties in $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it is assumed that there is no dependence of $\\Delta y$ on the value of $y$ itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_weights = 1/abs(np.random.normal(loc=y_sigma, scale=y_sigma/10, size=(n,)))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated slope -5.3260 \n",
      "Estimated intercept 10.4618 \n"
     ]
    }
   ],
   "source": [
    "sk_weighted_lm = linear_model.LinearRegression()\n",
    "sk_weighted_result = sk_weighted_lm.fit(x, y, sample_weight=y_weights)\n",
    "\n",
    "print(f\"Estimated slope {sk_weighted_result.coef_[0,0]:.4f} \\nEstimated intercept {sk_weighted_result.intercept_[0]:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.4942 ± 1.0083\n"
     ]
    }
   ],
   "source": [
    "residuals = y_row - (x_row * sk_weighted_result.coef_[0,0] + sk_weighted_result.intercept_[0])\n",
    "s_squared_value = sum(y_weights * residuals**2) / (n - p)\n",
    "\n",
    "y_estimated = x_to_predict * sk_weighted_result.coef_[0,0] + sk_weighted_result.intercept_[0]\n",
    "\n",
    "inner_sqrt_term = (x_to_predict_col_vec.T @ np.linalg.inv(x_design.T @ np.diag(y_weights) @ x_design ) @ x_to_predict_col_vec )[0,0]\n",
    "\n",
    "one_sided_CL_magnitude = stats.t.ppf(q = 1-(alpha/2), df = n-p) * np.sqrt(s_squared_value * inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_CL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.4942 ± 2.5394\n"
     ]
    }
   ],
   "source": [
    "one_sided_PL_magnitude = stats.t.ppf(q = 1-alpha/2, df = n-p) * np.sqrt(s_squared_value + s_squared_value * inner_sqrt_term)\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_PL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_weighted_lm = WLS(y, x_design, y_weights )\n",
    "sm_weighted_result = sm_weighted_lm.fit()\n",
    "# print(sm_weighted_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.4942 ± 1.0083\n"
     ]
    }
   ],
   "source": [
    "weighted_prediction = sm_weighted_result.get_prediction(x_to_predict_col_vec.T)\n",
    "\n",
    "y_estimated = weighted_prediction.predicted_mean[0]\n",
    "\n",
    "one_sided_CL_magnitude = weighted_prediction.summary_frame(alpha=alpha).mean_ci_upper.iloc[0] - weighted_prediction.predicted_mean[0]\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_CL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence level at x = 6 is y_estimated = -21.4942 ± 2.5394\n"
     ]
    }
   ],
   "source": [
    "one_sided_PL_magnitude = weighted_prediction.summary_frame(alpha=alpha).obs_ci_upper.iloc[0] - weighted_prediction.predicted_mean[0]\n",
    "\n",
    "print(f\"95% Confidence level at x = {x_to_predict} is y_estimated = {y_estimated:.4f} ± {one_sided_PL_magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the `statsmodels` approach is neater and preferred.\n",
    "\n",
    "`sklearn` is also fine to be used, but some manipulation needs to be done with the variables.\n",
    "\n",
    "Do not use `scipy.odr` since it does not perform an exact weighted least squares calculation to estimate the fit parameters and instead uses the Levenberg-Marquardt-type algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With uncertainties in $x$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_weights = 1/abs(np.random.normal(loc=x_sigma, scale=x_sigma/10, size=(n,)))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using `scipy.odr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_linear_function(params, x):\n",
    "    \"\"\"\n",
    "    Univariate linear calculation\n",
    "    Input: params (list) contain the linear coefficients\n",
    "    Input: x (row vector) contains the independent variables\n",
    "    Output: the linear calculation\n",
    "    \"\"\"\n",
    "\n",
    "    return params[0] + params[1] * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: [10.40553543 -5.33367186]\n",
      "Beta Std Error: [0.42445092 0.02755116]\n",
      "Beta Covariance: [[0.21446413 0.0046572 ]\n",
      " [0.0046572  0.00090361]]\n",
      "Residual Variance: 0.8400406388050697\n",
      "Inverse Condition #: 0.0020416657392539838\n",
      "Reason(s) for Halting:\n",
      "  Sum of squares convergence\n"
     ]
    }
   ],
   "source": [
    "odr_model = odr.Model(univariate_linear_function)\n",
    "\n",
    "odr_data = odr.RealData(x=x.flatten(), y=y.flatten(), sx=1/np.sqrt(x_weights), sy=1/np.sqrt(y_weights))\n",
    "\n",
    "odr_instance = odr.ODR(odr_data, odr_model, beta0=[1,30])\n",
    "\n",
    "odr_output = odr_instance.run()\n",
    "\n",
    "odr_output.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
